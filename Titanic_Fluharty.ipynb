{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survivor Prediction\n",
    "\n",
    "Based on https://www.kaggle.com/c/titanic competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages we will need to extend the capabilities of Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the two data files and convert them into Pandas Dataframes\n",
    "train = pd.read_csv(\"titanic_train.csv\")\n",
    "test = pd.read_csv(\"titanic_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the dimensions of the training dataframe\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId Survived Pclass    Name     Sex      Age  SibSp  Parch  Ticket  \\\n",
       "0       int64    int64  int64  object  object  float64  int64  int64  object   \n",
       "\n",
       "      Fare   Cabin Embarked  \n",
       "0  float64  object   object  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group the columns in the training data by type of data\n",
    "train.dtypes.to_frame().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first few rows of the training data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin       687\n",
       "Age         177\n",
       "Embarked      2\n",
       "Fare          0\n",
       "Ticket        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out a list of columns, sorted by their number of missing values\n",
    "train.isna().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin       327\n",
       "Age          86\n",
       "Fare          1\n",
       "Embarked      0\n",
       "Ticket        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out a list of columns, sorted by their number of missing values\n",
    "test.isna().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values for the cabin column with an indicator value\n",
    "for df in train, test:\n",
    "    df['Cabin'].fillna(value='NA',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute an age value for the individuals with no age listed, based on their values for three other features\n",
    "for df in train,test:\n",
    "    df[\"AgeImputed\"] = df.groupby(['Pclass', 'Sex','SibSp'])['Age'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the age column that is being replaced\n",
    "for df in train,test:\n",
    "    df.drop(['Age'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the few remaining missing values in the age column with the average value for age\n",
    "for df in train,test:\n",
    "    df['AgeImputed'] = df['AgeImputed'].fillna(value=9.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for replacing missing values in a categorical column with the most common value\n",
    "def fillcommon(cell):\n",
    "    common = cell.value_counts().head(1)\n",
    "    comdct = common.to_dict()\n",
    "    comkey = [k for k,v in comdct.items()]\n",
    "    cell.fillna(value=comkey[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the fillcommon function on the embarked categorical column\n",
    "for df in train,test:\n",
    "    fillcommon(df['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values in the fare column with the average value\n",
    "for df in train,test:\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering with Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a function that returns true or false depending on whether the family rented a cabin\n",
    "def hasCabin(cell):\n",
    "    if cell == 'NA':\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "for df in train,test:\n",
    "    df['Has_Cabin'] = df['Cabin'].apply(hasCabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# family size\n",
    "for df in train,test:\n",
    "    df['FamSize'] = df.Parch + df.SibSp + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a couple more measures of family size\n",
    "for df in train,test:\n",
    "    df['SmallFamily'] = df['FamSize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\n",
    "    df['LargeFamily'] = df['FamSize'].map(lambda s: 1 if 5 <= s else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    867\n",
       "2     16\n",
       "3      6\n",
       "4      2\n",
       "Name: CabinQuantForFam, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a function that counts the number of cabins per family\n",
    "def cabinsCount(lst):\n",
    "    itms = lst.split()\n",
    "    num = len(itms)\n",
    "    if num >1:\n",
    "        return num\n",
    "    else:\n",
    "        return 1\n",
    "for df in train,test:\n",
    "    df['CabinQuantForFam'] = df['Cabin'].apply(cabinsCount)\n",
    "train['CabinQuantForFam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    720\n",
       "C     59\n",
       "B     47\n",
       "D     33\n",
       "E     32\n",
       "Name: CabinLevel, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a function that extracts the most common first letters from the cabin column\n",
    "def getLevel(lst):\n",
    "    if lst[0] in ['C','B','D','E']:\n",
    "    #if lst[0] in ['A', 'C', 'B', 'E', 'D', 'G', 'F', 'U', 'T']:\n",
    "        return lst[0]\n",
    "    else:\n",
    "        return 'x'\n",
    "for df in train,test:\n",
    "    df['CabinLevel'] = df['Cabin'].apply(getLevel)\n",
    "train['CabinLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x      788\n",
       "100     40\n",
       "200     32\n",
       "300     31\n",
       "Name: CabinRoomZone, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a function that finds the zone of the room number, which comes from the cabin column\n",
    "def getRoom(lst):\n",
    "    itms = lst.split()\n",
    "    num = itms[0]\n",
    "    pre = num[1:2]\n",
    "    if pre=='1':\n",
    "        return '100'\n",
    "    elif pre=='2':\n",
    "        return '200'\n",
    "    elif pre=='3':\n",
    "        return '300'\n",
    "    else:\n",
    "        return 'x'\n",
    "for df in train,test:\n",
    "    df['CabinRoomZone'] = df['Cabin'].apply(getRoom)\n",
    "train['CabinRoomZone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NA     687\n",
       "C23      4\n",
       "G6       4\n",
       "F        4\n",
       "B96      4\n",
       "Name: RoomNumber, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the full room number for each passenger\n",
    "def RoomNum(lst):\n",
    "    itms = lst.split()\n",
    "    num = itms[0]\n",
    "    room = num # [1:]\n",
    "    return room\n",
    "for df in train,test:\n",
    "    df['RoomNumber'] = df['Cabin'].apply(RoomNum)\n",
    "train['RoomNumber'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabulate the number of people sharing the room for each family\n",
    "traincounts = train['RoomNumber'].value_counts()\n",
    "testcounts = test['RoomNumber'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link each room number with the number of families sharing it\n",
    "trdct = traincounts.to_dict() \n",
    "tedct = testcounts.to_dict() \n",
    "\n",
    "def TrainRoomCount(cell):\n",
    "    cell = str(cell)\n",
    "    if cell == 'NA':\n",
    "        return 'NA'\n",
    "    else:\n",
    "        return trdct.get(cell)\n",
    "\n",
    "def TestRoomCount(cell):\n",
    "    cell = str(cell)\n",
    "    if cell == 'NA':\n",
    "        return 'NA'\n",
    "    else:\n",
    "        return tedct.get(cell)\n",
    "\n",
    "train['NumFamInRoom'] = train['RoomNumber'].apply(TrainRoomCount)\n",
    "test['NumFamInRoom'] = test['RoomNumber'].apply(TestRoomCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lower_deck     692\n",
       "upper_deck     121\n",
       "middle_deck     78\n",
       "Name: CabinDeck, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a function that assigns the passengers to deck levels, based on their values in the cabin column\n",
    "def getDeck(lst):\n",
    "    if lst[0] in ['C','B','A']:\n",
    "        return 'upper_deck'\n",
    "    elif lst[0] in ['D','E','F']:\n",
    "        return 'middle_deck'\n",
    "    else:\n",
    "        return 'lower_deck'\n",
    "for df in train,test:\n",
    "    df['CabinDeck'] = df['Cabin'].apply(getDeck)\n",
    "train['CabinDeck'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops the cabin column after its replacements have been created and added to the dataframe\n",
    "for df in train,test:\n",
    "    df.drop(['Cabin','RoomNumber'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recodes the numeric values in the Pclass column with more descriptive categories\n",
    "Pclass = {1:'first_class',2:'second_class',3:'third_class'}\n",
    "for df in train,test:\n",
    "    df['Pclass'] = df['Pclass'].map(Pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recodes the single-character values in the embarked column with more descriptive categories\n",
    "embark = {'C':'Cherbourg','Q':'Queenstown','S':'Southampton'}\n",
    "for df in train,test:\n",
    "    df['Embarked'] = df['Embarked'].map(embark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recodes the numeric values in the Cabin Room Zone column with more descriptive categories\n",
    "crz = {'x':'unknown','100':'one hundreds','200':'two hundreds','300':'three hundreds'}\n",
    "for df in train,test:\n",
    "    df['CabinRoomZone'] = df['CabinRoomZone'].map(crz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering with Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    714\n",
       "s     65\n",
       "p     65\n",
       "c     47\n",
       "Name: TicketLetter, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a function that extracts the most common first letters from the ticket column\n",
    "def getLetter(text):\n",
    "    # lower case\n",
    "    text = text.lower()          \n",
    "    # remove digits and punctuation\n",
    "    regex = re.compile(r\"[%s%s]\" % (string.punctuation, string.digits))\n",
    "    text = regex.sub('', text)\n",
    "    if text=='':\n",
    "        return 'x'\n",
    "    elif text[0] in ['p','s','c']:\n",
    "        return text[0]\n",
    "    else:\n",
    "        return 'x'\n",
    "for df in train,test:\n",
    "    df['TicketLetter'] = df['Ticket'].apply(getLetter)\n",
    "train['TicketLetter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2343       7\n",
       "347082     7\n",
       "1601       7\n",
       "2144       6\n",
       "3101295    6\n",
       "Name: TicketNum, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a function that extracts the numeric portion of the ticket number\n",
    "def getNumber(num):\n",
    "    # remove punctuation, a-z letters, and whitespace\n",
    "    regex = re.compile(r\"[%s%s%s]\" % (string.punctuation,string.ascii_letters,string.whitespace))\n",
    "    numbers = regex.sub('', num)\n",
    "    return numbers\n",
    "for df in train,test:\n",
    "    df['TicketNum'] = df['Ticket'].apply(getNumber)\n",
    "train['TicketNum'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     419\n",
       "5     131\n",
       "4     101\n",
       "8      76\n",
       "10     41\n",
       "Name: TickLen, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the length of the ticket characters and numbers \n",
    "for df in train,test:\n",
    "    df['TickLen'] = df['Ticket'].apply(len)\n",
    "train['TickLen'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    439\n",
       "5    242\n",
       "4    154\n",
       "7     24\n",
       "8     20\n",
       "Name: TickNumLen, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the length of the ticket number\n",
    "for df in train,test:\n",
    "    df['TickNumLen'] = df['TicketNum'].apply(len)\n",
    "train['TickNumLen'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    337\n",
       "1    227\n",
       "2    220\n",
       "x    107\n",
       "Name: TicketFirstNum, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a function that extracts the first digit of the ticket number\n",
    "def getFirstNum(num):\n",
    "    # remove punctuation\n",
    "    regex = re.compile(r\"[%s]\" % (string.punctuation))\n",
    "    num = regex.sub('', num)\n",
    "    # detect numbers\n",
    "    numbers = re.findall('[0-9]+', num)\n",
    "    if len(numbers)>1:\n",
    "        return 'x'\n",
    "    elif len(numbers)==1:\n",
    "        numstr = str(numbers[0])\n",
    "        if numstr[0:1] in ['1','2','3']:\n",
    "            return numstr[0:1]\n",
    "        else:\n",
    "            return 'x'\n",
    "    else:\n",
    "        return 'x'\n",
    "for df in train,test:\n",
    "    df['TicketFirstNum'] = df['Ticket'].apply(getFirstNum)\n",
    "train['TicketFirstNum'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a function that extracts the first two digits of the ticket number\n",
    "def getFirstTwoNum(num):\n",
    "    # remove punctuation\n",
    "    regex = re.compile(r\"[%s]\" % (string.punctuation))\n",
    "    num = regex.sub('', num)\n",
    "    # detect numbers\n",
    "    numbers = re.findall('[0-9]+', num)\n",
    "    if len(numbers)>1:\n",
    "        return 'x'\n",
    "    elif len(numbers)==1:\n",
    "        numstr = str(numbers[0])\n",
    "        if numstr[0:1] in ['1','2','3']:\n",
    "            return numstr[0:2]\n",
    "        else:\n",
    "            return 'x'\n",
    "    else:\n",
    "        return 'x'\n",
    "for df in train,test:\n",
    "    df['TicketFirstTwoNum'] = df['Ticket'].apply(getFirstTwoNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most common values for the first two digits of the ticket number\n",
    "trtckcts = train['TicketFirstTwoNum'].value_counts().head(3) \n",
    "tetckcts = test['TicketFirstTwoNum'].value_counts().head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link each room number with the number of families sharing it\n",
    "trtckdct = trtckcts.to_dict() \n",
    "tetckdct = tetckcts.to_dict() \n",
    "\n",
    "def TrainTckFirstTwoNumCount(cell):\n",
    "    cell = str(cell)\n",
    "    if cell in trtckdct.keys():\n",
    "        return cell\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "def TestTckFirstTwoNumCount(cell):\n",
    "    cell = str(cell)\n",
    "    if cell in tetckdct.keys():\n",
    "        return cell\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "train['TicketFirstTwo'] = train['TicketFirstTwoNum'].apply(TrainTckFirstTwoNumCount)\n",
    "test['TicketFirstTwo'] = test['TicketFirstTwoNum'].apply(TestTckFirstTwoNumCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop various ticket columns after their replacements have been added to the dataframe\n",
    "for df in train,test:\n",
    "    df.drop(['Ticket','TicketNum','TicketFirstTwoNum'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Names and Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the length of the name field for each family\n",
    "for df in train,test:\n",
    "    df['NameLen'] = df['Name'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.                 517\n",
       "Miss.               185\n",
       "Mrs.                135\n",
       "Upper_Class_Male     54\n",
       "Name: FamilyHeadTitle, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a function that assigns the various family head titles to a few basic categories\n",
    "def getTitle(name):\n",
    "    if pd.notna(name):\n",
    "        regex = re.compile(r\"\\b\\w+[.]\")\n",
    "        title = regex.findall(name)\n",
    "        #return title[0]\n",
    "        if title[0] in ['Mr.','Miss.','Mrs.']:\n",
    "            return title[0]\n",
    "        elif title[0] in ['Master.','Rev.','Major.','Col.','Don.','Jonkheer.','Sir.','Capt.']:\n",
    "            return 'Upper_Class_Male'\n",
    "        elif title[0] in ['Mlle.','Ms.']:\n",
    "            return 'Miss.'\n",
    "        elif title[0] in ['Mme.','Countess.','Dr.','Lady.']:\n",
    "            return 'Mrs.'\n",
    "        else:\n",
    "            return np.nan\n",
    "for df in train,test:\n",
    "    df['FamilyHeadTitle'] = df['Name'].apply(getTitle)\n",
    "train['FamilyHeadTitle'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       braund\n",
       "1      cumings\n",
       "2    heikkinen\n",
       "3     futrelle\n",
       "4        allen\n",
       "Name: Surname, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a function that extracts the surname for further processing\n",
    "def getSurname(text):\n",
    "    # lower case\n",
    "    text = text.lower()          \n",
    "    # remove digits and punctuation\n",
    "    regex = re.compile(r\"[%s%s]\" % (string.punctuation, string.digits))\n",
    "    text = regex.sub('', text)\n",
    "    first = text.split()\n",
    "    name = first[0]\n",
    "    return name\n",
    "for df in train,test:\n",
    "    df['Surname'] = df['Name'].apply(getSurname)\n",
    "train['Surname'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports demographic data that can be added to the surnames\n",
    "census1 = pd.read_csv('first third.csv')\n",
    "census2 = pd.read_csv('second third.csv')\n",
    "census3 = pd.read_csv('third third.csv')\n",
    "census = pd.concat([census1, census2, census3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       smith\n",
       "1     johnson\n",
       "2    williams\n",
       "3       brown\n",
       "4       jones\n",
       "Name: lower_name, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converts the surnames in the demographic data to lowercase\n",
    "def makeLower(cell):\n",
    "    cell = str(cell)\n",
    "    cell = cell.lower()\n",
    "    return cell\n",
    "census['lower_name'] = census['name'].apply(makeLower)\n",
    "census['lower_name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops the name column, once its replacement has been added, as well as a few other unnecessary columns\n",
    "census = census.drop(['name','rank','count','prop100k','cum_prop100k'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaces missing values, for small sample sizes, with zeroes\n",
    "for col in census:\n",
    "    census[col] = census[col].replace(to_replace='(S)', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins the reprocessed census data to the train and test data, using the lower-cased surnames as a common key\n",
    "train = train.join(census.set_index('lower_name'), on='Surname', how='left')\n",
    "test = test.join(census.set_index('lower_name'), on='Surname', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the values from several of the new columns from the census data into float numbers\n",
    "numcols = ['pctwhite','pctblack','pctapi','pctaian','pct2prace','pcthispanic']\n",
    "for df in train,test:\n",
    "    for col in numcols:\n",
    "        df[col] = df[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values in the new census columns, based on the values for three other features\n",
    "for df in train,test:\n",
    "    for col in numcols:\n",
    "        df[col] = df.groupby(['Pclass', 'AgeImputed','Embarked'])[col].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace any remaining missing values in the new census columns with their average value\n",
    "for df in train,test:\n",
    "    for col in numcols:\n",
    "        df[col].fillna(df[col].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the name and surname columns, which are no longer needed for analysis\n",
    "for df in train,test:\n",
    "    df.drop(['Name','Surname'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering of Feature Interaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new features based on interactions between features\n",
    "for df in train,test:\n",
    "    df[\"AdultMale\"] = ((df[\"Sex\"] == \"male\")&(df[\"AgeImputed\"]>18))*1\n",
    "    df[\"AdultFemale\"] = ((df[\"Sex\"] == \"female\")&(df[\"AgeImputed\"]>18))*1\n",
    "    df[\"IsBaby\"] = (df[\"AgeImputed\"]<2)*1\n",
    "    df[\"IsLoner\"] = ((df[\"AgeImputed\"] >= 18) & (df[\"SibSp\"] == 0) & (df[\"Parch\"]==0))*1\n",
    "    df[\"IsChild\"] = ((df[\"AgeImputed\"]>2)&(df[\"AgeImputed\"]<18))*1\n",
    "    df['Immed&ExtendFam'] = ((df[\"SibSp\"]>0)&(df[\"Parch\"]>0))*1\n",
    "    df[\"FamilyMan\"] = ((df[\"Sex\"] == \"male\")&(df[\"SibSp\"]>0)&(df[\"Parch\"]>0))*1\n",
    "    df[\"FamilyWoman\"] = ((df[\"Sex\"] == \"female\")&(df[\"SibSp\"]>0)&(df[\"Parch\"]>0))*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning numerical columns\n",
    "for df in train,test:\n",
    "    df['FareBin'] = pd.qcut(df.Fare, q=4, labels=False,duplicates='drop')\n",
    "    df['AgeBin'] = pd.qcut(df.AgeImputed, q=4, labels=False,duplicates='drop')\n",
    "    df['FamSizeBin'] = pd.qcut(df.FamSize, q=4, labels=False,duplicates='drop')\n",
    "    df['TickLenBin'] = pd.qcut(df.TickLen, q=4, labels=False,duplicates='drop')\n",
    "    df['TickNumLenBin'] = pd.qcut(df.TickNumLen, q=4, labels=False,duplicates='drop')\n",
    "    df['pctwhiteBin'] = pd.qcut(df.pctwhite, q=4, labels=False,duplicates='drop')\n",
    "    df['pctblackBin'] = pd.qcut(df.pctblack, q=4, labels=False,duplicates='drop')\n",
    "    df['pcthispanicBin'] = pd.qcut(df.pcthispanic, q=4, labels=False,duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns that are no longer needed after binning\n",
    "for df in train,test:\n",
    "    df.drop(['Fare','AgeImputed','FamSize','TickLen','TickNumLen','pctwhite','pctblack',\n",
    "             'pcthispanic'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collapsing Sex into One Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicate sex column\n",
    "for df in train,test:\n",
    "    df['Sex'] = df.Sex.apply(lambda x: 0 if x == \"female\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a list of categorical columns to add dummy columns\n",
    "train2 = train.drop(['Survived'], axis=1)\n",
    "catCols = train2.select_dtypes(exclude=[\"number\"])\n",
    "categorical_features = list(catCols.columns)\n",
    "test2 = test\n",
    "catCols2 = test2.select_dtypes(exclude=[\"number\"])\n",
    "categorical_features2 = list(catCols2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dummy columns and drop the first one of each set to minimize multicollinearity\n",
    "Xtraincat= pd.get_dummies(train2[categorical_features],drop_first=True)\n",
    "train = pd.concat([train, Xtraincat], axis=1)\n",
    "train = train.drop(categorical_features,axis=1)\n",
    "Xtestcat= pd.get_dummies(test2[categorical_features],drop_first=True)\n",
    "test = pd.concat([test, Xtestcat], axis=1)\n",
    "test = test.drop(categorical_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns from the training data that are not in the test data and print dimensions\n",
    "# to ensure the training data has just one more column (the target) than the test data\n",
    "testCols = list(test.columns)\n",
    "trainCols = list(train.columns)\n",
    "trainCols.remove('Survived')\n",
    "extraTrain = list(set(trainCols)-set(testCols))\n",
    "train = train.drop(extraTrain,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the train data for validation of the model\n",
    "X = train.drop(['Survived'], axis=1)\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train data\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following code to deal with SettingWithCopyWarning\n",
    "Xtrain = Xtrain.copy()\n",
    "Xtest = Xtest.copy()\n",
    "ytrain = ytrain.copy()\n",
    "ytest = ytest.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate the classifier object\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run grid search for cross-validation purposes\n",
    "param_grid = {\n",
    "    'learning_rate':[0.095,0.1,0.105],\n",
    "    'max_depth':[2,3,4],\n",
    "    'n_estimators':[90,100,110]\n",
    "}\n",
    "gscv = GridSearchCV(xgb, param_grid, iid=False, cv=4, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'learning_rate': [0.095, 0.1, 0.105], 'max_depth': [2, 3, 4], 'n_estimators': [90, 100, 110]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "gscv.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the best prediction to a variable\n",
    "ypred = gscv.best_estimator_.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8212290502793296\n",
      "\n",
      "confusion matrix:\n",
      "[[97  9]\n",
      " [23 50]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       106\n",
      "           1       0.85      0.68      0.76        73\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       179\n",
      "   macro avg       0.83      0.80      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the summary statistics for the validation prediction\n",
    "print (\"accuracy score:\",metrics.accuracy_score(ytest, ypred))\n",
    "print()\n",
    "print (\"confusion matrix:\")\n",
    "print (metrics.confusion_matrix(ytest, ypred))\n",
    "print()\n",
    "print (\"classification report:\")\n",
    "print (metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a DataFrame for the submission file\n",
    "submission = pd.DataFrame(test['PassengerId'])\n",
    "submission['Survived'] = gscv.best_estimator_.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the submission dataframe into a csv file, formatted as Kaggle requires\n",
    "submission.to_csv('submission.csv',index=False,index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The submission file has been saved to the same folder as this program.\n"
     ]
    }
   ],
   "source": [
    "print(\"The submission file has been saved to the same folder as this program.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
